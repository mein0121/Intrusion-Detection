1. 데이터셋 설명 및 이용 목적

우리가 선택한 데이터셋의 이름은 Intrusion Detection, 즉 침입 감지로 네트워크에 감지된 연결들의 상태를 분석해 어떤 연결이 비정상인지를 알아보는 것이 주 목적이다. 본 데이터셋은 실제 환경이 아니라 군 네트워크 환경에서 시뮬레이션된 침입들로 일반적인 미 공군 LAN 환경을 모방한 환경에서 실행된 결과라고 한다. 각 연결 기록은 대략 100 바이트 정도이고 이 연결들로부터 우리는 그 연결이 normal인지 anormaly인지를 구별하고, 차후에 있을 연결들이 normal인지 anomaly인지 판단할 수 있는 가장 정확도가 높은 모델이 어떤 것이지 선정하고자 본 프로젝트를 진행했다.


3. 데이터셋 전처리 방법 및 선택 이유

자료를 살펴보면 대다수의 값이 자연수이거나 실수값이고 문자열 값은 네 개뿐이다. 그리고 컬럼 수는 총 41개로 많은 편이다. 그렇기 때문에 컬럼을 더 늘리는 원핫 인코딩보다는 레이블 인코딩을 선택했었다. 자연수와 실수값으로만 이루어진 컬럼들과 문자열 컬럼을 분리해 문자열 컬럼에만 레이블 인코딩을 적용하고 자연수와 실수 컬럼은 일단 그대로 두었다. 그러나 후에 우리가 선택해 사용해본 모델 중 svm과 로지스틱 회귀는 레이블 인코딩을 사용하면 안된다는 점을 알게 되어 그 두 모델은 원핫인코딩을 적용한 데이터셋을 가지고 모델을 돌렸다.

그리고 자료를 살펴보면 숫자들의 최대치와 최소치의 차이가 굉장히 크기 때문에 보다 정확한 결과를 위해 scaling이 필요했는데 scaling 방법으로는 StandardScaler을 이용했다. StandardScaling은 레이블 인코딩을 마친 문자열 컬럼을 제외한 나머지 숫자 컬럼들에만 적용했고 scaling 적용 후 두 데이터셋을 합쳐 데이터 전처리를 완료했다.

그리고 컬럼 수가 너무 많기 때문에 필요없는 컬럼을 줄이고자 데이터셋 내에서 각 feature 간의 관계도를 correlation 함수를 통해 확인하고 먼저 NaN 값을 가진 컬럼을 삭제 후 연관성이 높은 컬럼들과 비교해 현저히 낮은 값을 가진 컬럼들을 삭제하고 테스트해보는 방식으로 컬럼들을 줄여나갔다. 그렇게 최종적으로 30개의 컬럼을 남기게 되었다.

또 이용하려고 했던 방법으로 pca라고 하는 차원축소법이 있는데 이 방법 같은 경우 위에서 했던 방법들처럼 컬럼을 삭제하는 것이 아니라 각 컬럼들 간에 가장 잘 맞는 특정한 축을 찾아내어 새롭게 데이터셋을 구성해주는 방법이다. 이 방법 같은 경우 컬럼들이 완전히 새롭게 바뀌게 되기 때문에 프로젝트에 혼선을 줄 것 같아 이용만 해본 방법이다.

이렇게 새롭게 만들어진 데이터셋을 우리는 세 개의 셋으로 다시 나눴는데 train, validation, 그리고 test이다. 우리가 가진 데이터셋의 경우 train과 test 데이터가 이미 나눠져 있는데 이 test 데이터에는 target 컬럼이 없다. 마지막에 모델 작동을 확인하기 위한 최종 데이터셋이다. 그렇기 때문에 기존의 train 데이터를 train과 validation 뿐만이 아닌 test로도 나눠서 사용했다. 데이터를 나눌 때는 먼저 train과 validation을 3대1로 나누고 또 다시 train을 train과 test로 나눴다. train : val : test의 비율이 9 : 5 : 3 정도가 된다. 레이블 인코딩과 원핫 인코딩 둘 다 사용했기 때문에 두 데이터셋 모두 세 개로 나눴다.

4. KNN 모델 및 파라미터 설명

KNN은 본래 분류되어 있던 자료들에 새로운 값이 추가될 때마다 우리가 설정해준 값에 맞춰 어느 그룹에 더 가까운지를 알려주는 모델이다.

'n_neighbors':range(4,7) #Feature수의 제곱근 정도를 지정할 때 성능이 좋은 것으로 알려져 있기 때문에 현재 가진 data set의 30개 feature의 제곱근 값에 가깝게, 그러나 조금 널널하게 설정

'Weights':['uniform', 'distance'] #모든 이웃에게 동일한 가중치를 주었을 때와 가까운 이웃에게 더 많은 가중치를 주었을 때 모두의 상황을 확인

'leaf_size':range(20,30) #너무 크면 성능이 낮아지고 너무 작으면 오래 걸리게 되지만 이번 분류는 오래 걸리더라도 더 높은 정확도를 요구하는 주제이기 때문에 default 값인 30보다 아래쪽에서 수를 선정

algorithm, metric, p, metric_params는 default값으로



5. Light GBM 모델 및 파라미터 설명
LightGBM은 GradientBoosting 계열의 모델로 Tree기반 알고리즘이다. 기존 GB에서 단점을 보완해 큰 데이터셋에 사용할 때도 비교적 빠른 속도로 일을 처리할 수 있는 모델이다. 다만 과적합에 민감해 1만개 이하의 행을 가진 데이터에는 적합하지 않다고 한다. 우리가 가진 데이터는 2만개가 조금 넘는 행을 가지고 있어 기준에는 부합했다. 파라미터가 많아 초보자가 사용하기엔 어렵다는 단점이 있는데 그렇기 때문에 우리도 가장 중요하다고 하는 하이퍼파라미터만 조정해 사용해보았다.


'min_data_in_leaf':range(100,200) #overfitting 예방하는 param. 10000건 이상의 dataset에서는 보통 100~1000의 값을 사용(default=20)

'num_leaves':[31] #tree모델의 복잡성을 조절. (default=31)

'max_depth':(default=-1) #가능한 한 -1을 이용해 최대 depth를 알아보는 것이 좋음

# 더 높은 정확도를 위해 max_bin이나 num_leaves 값을 크게 준다거나 dart라는 옵션을 쓸 수 있지만 이 파라미터로 이미 충분한 정확도를 얻었다고 생각되어 하이퍼 파라미터를 더 추가하지 않았음
